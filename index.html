<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>A Unified Framework for High-Frame-Rate HDR Video Synthesis</title>
  <link rel="stylesheet" href="/assets/css/style.css" />
</head>
<body>
  <header class="site-header">
    <div class="container">
      <h1 class="title">A Unified Framework for High-Frame-Rate HDR Video Synthesis</h1>
      <p class="subtitle">Real-time HDR reconstruction + temporal interpolation from alternating-exposure video</p>
      <nav class="links">
        <a href="https://bmva-archive.org.uk/bmvc/2025/assets/papers/Paper_824/paper.pdf" target="_blank">Paper (PDF)</a>
        <a href="https://bmva-archive.org.uk/bmvc/2025/assets/papers/Paper_824/poster.pdf" target="_blank">Poster</a>
        <a href="#video" target="_blank">Video (placeholder)</a>
        <a href="https://github.com/huent189/unified-HFR-HDR" target="_blank">Code (@huent189/unified-HFR-HDR)</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <section id="abstract" class="card">
      <h2>Abstract</h2>
      <p>Capturing high dynamic range (HDR) video at high frame rates is critical for applications such as cinematic production and autonomous systems, yet it remains challenging with conventional cameras. We present the first unified framework that jointly performs HDR reconstruction and temporal interpolation from sequences with alternating exposures. Unlike prior work that reconstructs only middle frames or uses heavy off-the-shelf interpolators, our lightweight network synthesizes HDR video at arbitrary timesteps in real time on mid-range GPUs. To support this task, we introduce a new dataset of exposure-bracketed video sequences with real-world motion. To reduce reliance on ground-truth HDR data, we also propose a novel self-supervised training scheme that delivers competitive results. Experiments show our approach outperforms existing baselines in efficiency while achieving comparable or better visual quality, establishing a new benchmark for practical HDR video synthesis.</p>
    </section>

    <section id="examples" class="card">
      <h2>Example Results</h2>
      <p>Below are a few example results (placeholders). Replace these images with your rendered outputs for the final site.</p>
      <div class="gallery">
        <figure>
          <img src="https://via.placeholder.com/800x450?text=Example+1" alt="Example 1" />
          <figcaption>Example 1 — alternating exposures -> synthesized HDR frame (placeholder)</figcaption>
        </figure>
        <figure>
          <img src="https://via.placeholder.com/800x450?text=Example+2" alt="Example 2" />
          <figcaption>Example 2 — HDR interpolation across timesteps (placeholder)</figcaption>
        </figure>
        <figure>
          <img src="https://via.placeholder.com/800x450?text=Example 3" alt="Example 3" />
          <figcaption>Example 3 — real-world motion sequence (placeholder)</figcaption>
        </figure>
      </div>
    </section>

    <section id="download" class="card">
      <h2>Downloads & Resources</h2>
      <ul>
        <li><a href="https://bmva-archive.org.uk/bmvc/2025/assets/papers/Paper_824/paper.pdf" target="_blank">Paper (PDF)</a></li>
        <li><a href="https://bmva-archive.org.uk/bmvc/2025/assets/papers/Paper_824/poster.pdf" target="_blank">Poster (PDF)</a></li>
        <li><a href="https://github.com/huent189/unified-HFR-HDR" target="_blank">Code repository</a></li>
      </ul>
    </section>

    <footer class="card footer">
      <p>Site generated for the BMVC 2025 paper. Color accent: blue. Hosted on GitHub Pages.</p>
    </footer>
  </main>
</body>
</html>